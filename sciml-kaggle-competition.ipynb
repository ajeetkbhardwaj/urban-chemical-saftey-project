{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":89841,"databundleVersionId":10433199,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Urban Chemical Safety Challenge: PINN Baseline Notebook**\n\nThis notebook demonstrates solving the Convection-Diffusion equation using Physics-Informed Neural Networks (PINNs).\nThe solution includes:\n1. Problem Setup\n3. PINN Model Definition\n4. Training Loop\n6. Submission File Creation","metadata":{}},{"cell_type":"code","source":"# --- IMPORTS ---\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd \nimport os\nimport subprocess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:36:37.585716Z","iopub.execute_input":"2024-12-13T04:36:37.586288Z","iopub.status.idle":"2024-12-13T04:36:37.590867Z","shell.execute_reply.started":"2024-12-13T04:36:37.586248Z","shell.execute_reply":"2024-12-13T04:36:37.589877Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.activations import swish, mish","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:36:37.591971Z","iopub.execute_input":"2024-12-13T04:36:37.592316Z","iopub.status.idle":"2024-12-13T04:36:37.603144Z","shell.execute_reply.started":"2024-12-13T04:36:37.592278Z","shell.execute_reply":"2024-12-13T04:36:37.602414Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# --- CONFIGURABLE PARAMETERS ---\n# Domain boundaries\nx_min, x_max = 0.0, 1.0  # x-coordinate bounds\ny_min, y_max = 0.0, 1.0  # y-coordinate bounds\neps = 1e-4  # Diffusion coefficient\n\n# Neural network architecture and training parameters\nlayers = [2, 30, 1]  # Network architecture: [input_dim, hidden_dim, output_dim]\nlr_initial = 0.01    # Initial learning rate for Adam optimizer\nepochs = 10000        # Number of training epochs\nbeta = 1.0          # Weight for boundary condition loss term\n\n# Sampling parameters\nN_interior = 1000    # Number of interior training points\nN_boundary = 100     # Number of boundary training points\n\n# File paths\ntest_path = \"../input/casml-2024-scientific-machine-learning-challenge/test.csv\"\nsubmission_path = \"/kaggle/working/submission.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:12:58.210693Z","iopub.execute_input":"2024-12-13T06:12:58.211597Z","iopub.status.idle":"2024-12-13T06:12:58.216714Z","shell.execute_reply.started":"2024-12-13T06:12:58.211559Z","shell.execute_reply":"2024-12-13T06:12:58.215705Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"def set_device():\n    \"\"\"\n    Configure and select the computational device (GPU/CPU).\n    \n    Returns:\n        str: Device identifier ('/GPU:0' or '/CPU:0')\n    \"\"\"\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        print(\"Using GPU\")\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        return '/GPU:0'\n    print(\"Using CPU\")\n    return '/CPU:0'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:00.561436Z","iopub.execute_input":"2024-12-13T06:13:00.562153Z","iopub.status.idle":"2024-12-13T06:13:00.566584Z","shell.execute_reply.started":"2024-12-13T06:13:00.562122Z","shell.execute_reply":"2024-12-13T06:13:00.565699Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"device = set_device()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:02.732934Z","iopub.execute_input":"2024-12-13T06:13:02.733592Z","iopub.status.idle":"2024-12-13T06:13:02.738772Z","shell.execute_reply.started":"2024-12-13T06:13:02.733556Z","shell.execute_reply":"2024-12-13T06:13:02.737668Z"}},"outputs":[{"name":"stdout","text":"Using GPU\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"def generate_boundary_points(xmin, xmax, ymin, ymax, num_points):\n    \"\"\"\n    Generate training points along the domain boundaries.\n    \n    Args:\n        xmin, xmax (float): x-coordinate bounds\n        ymin, ymax (float): y-coordinate bounds\n        num_points (int): Total number of boundary points to generate\n    \n    Returns:\n        tuple: Arrays of x and y coordinates for boundary points\n    \"\"\"\n    num_points_per_edge = num_points // 4\n    # Generate points for each boundary edge\n    x_left = np.full((num_points_per_edge, 1), xmin)\n    y_left = np.random.uniform(ymin, ymax, (num_points_per_edge, 1))\n    x_right = np.full((num_points_per_edge, 1), xmax)\n    y_right = np.random.uniform(ymin, ymax, (num_points_per_edge, 1))\n    x_bottom = np.random.uniform(xmin, xmax, (num_points_per_edge, 1))\n    y_bottom = np.full((num_points_per_edge, 1), ymin)\n    x_top = np.random.uniform(xmin, xmax, (num_points_per_edge, 1))\n    y_top = np.full((num_points_per_edge, 1), ymax)\n    \n    # Stack all boundary points\n    x_boundary = np.vstack([x_left, x_right, x_bottom, x_top])\n    y_boundary = np.vstack([y_left, y_right, y_bottom, y_top])\n    return x_boundary, y_boundary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:04.659302Z","iopub.execute_input":"2024-12-13T06:13:04.659655Z","iopub.status.idle":"2024-12-13T06:13:04.666044Z","shell.execute_reply.started":"2024-12-13T06:13:04.659624Z","shell.execute_reply":"2024-12-13T06:13:04.665021Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"def u_bc(x, y):\n    \"\"\"\n    Define the Dirichlet boundary condition.\n    \n    Args:\n        x (tf.Tensor): x-coordinates of boundary points\n        y (tf.Tensor): y-coordinates of boundary points\n    \n    Returns:\n        tf.Tensor: Boundary values (zero in this case)\n    \"\"\"\n    return np.zeros_like(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:06.617639Z","iopub.execute_input":"2024-12-13T06:13:06.618239Z","iopub.status.idle":"2024-12-13T06:13:06.622410Z","shell.execute_reply.started":"2024-12-13T06:13:06.618205Z","shell.execute_reply":"2024-12-13T06:13:06.621488Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def f(x, y):\n    \"\"\"\n    Define the forcing function for the PDE.\n    \n    Args:\n        x (tf.Tensor): x-coordinates\n        y (tf.Tensor): y-coordinates\n    \n    Returns:\n        tf.Tensor: Values of the forcing function at given points\n    \"\"\"\n    return 2*eps*(-x + np.exp(2*(x - 1)/eps)) + x*y**2 + 6*x*y - x*np.exp(3*(y - 1)/eps) - y**2*np.exp(2*(x - 1)/eps) + 2*y**2 - 6*y*np.exp(2*(x - 1)/eps) - 2*np.exp(3*(y - 1)/eps) + np.exp((2*x + 3*y - 5)/eps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:07.532137Z","iopub.execute_input":"2024-12-13T06:13:07.532784Z","iopub.status.idle":"2024-12-13T06:13:07.538176Z","shell.execute_reply.started":"2024-12-13T06:13:07.532750Z","shell.execute_reply":"2024-12-13T06:13:07.537298Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"\"\"\"   \n\n\"\"\"\n# Define the PINN neural network\nclass PINN(tf.keras.Model):\n    def __init__(self):\n        super(PINN, self).__init__()\n        self.dense1 = tf.keras.layers.Dense(256, activation='tanh', kernel_initializer='glorot_normal')\n        self.dense2 = tf.keras.layers.Dense(128, activation='tanh', kernel_initializer='glorot_normal')\n        self.dense3 = tf.keras.layers.Dense(, activation='tanh', kernel_initializer='glorot_normal')\n        self.dense4 = tf.keras.layers.Dense(1, kernel_initializer='glorot_normal')\n\n    def call(self, x, y):\n        # Ensure x and y are 1D tensors\n        x = tf.reshape(x, [-1])  # Shape: (batch_size,)\n        y = tf.reshape(y, [-1])  # Shape: (batch_size,)\n        # Expand dimensions to make x and y 2D tensors\n        x = tf.expand_dims(x, axis=-1)  # Shape: (10000, 1)\n        y = tf.expand_dims(y, axis=-1)  # Shape: (10000, 1)\n\n    # Concatenate along axis 1\n    #xy = tf.concat([x, y], axis=1)  # Shape: (10000, 2)\n        xy = tf.concat([x, y], axis=1)\n        h = self.dense1(xy)\n        h = self.dense2(h)\n        h = self.dense3(h)\n        u = self.dense4(h)\n        return u","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:59:46.643405Z","iopub.execute_input":"2024-12-12T14:59:46.644170Z","iopub.status.idle":"2024-12-12T14:59:46.650960Z","shell.execute_reply.started":"2024-12-12T14:59:46.644136Z","shell.execute_reply":"2024-12-12T14:59:46.649899Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def sine_activation(x):\n    return tf.sin(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:38:59.389012Z","iopub.execute_input":"2024-12-13T04:38:59.389861Z","iopub.status.idle":"2024-12-13T04:38:59.393601Z","shell.execute_reply.started":"2024-12-13T04:38:59.389828Z","shell.execute_reply":"2024-12-13T04:38:59.392672Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class PINN(tf.keras.Model):\n    def __init__(self):\n        super(PINN, self).__init__()\n        \n        # Layers with sine activation\n        self.dense1 = tf.keras.layers.Dense(100, activation='swish', kernel_initializer='glorot_normal')\n        self.norm1 = tf.keras.layers.LayerNormalization()\n        self.dense2 = tf.keras.layers.Dense(100, activation='swish', kernel_initializer='glorot_normal')\n        self.norm2 = tf.keras.layers.LayerNormalization()\n        self.dense3 = tf.keras.layers.Dense(100, activation='swish', kernel_initializer='glorot_normal')\n        self.norm3 = tf.keras.layers.LayerNormalization()\n        \n        # Residual layer\n        self.dense_residual = tf.keras.layers.Dense(100, activation='linear', kernel_initializer='glorot_normal')\n        \n        # Final output layer\n        self.dense4 = tf.keras.layers.Dense(1, kernel_initializer='glorot_normal')\n\n    def call(self, x, y):\n        # Ensure x and y are 1D tensors\n        x = tf.reshape(x, [-1])  # Shape: (batch_size,)\n        y = tf.reshape(y, [-1])  # Shape: (batch_size,)\n        x = tf.expand_dims(x, axis=-1)  # Shape: (batch_size, 1)\n        y = tf.expand_dims(y, axis=-1)  # Shape: (batch_size, 1)\n\n        # Concatenate inputs\n        xy = tf.concat([x, y], axis=1)  # Shape: (batch_size, 2)\n\n        # Forward pass with normalization and residual connection\n        h = self.dense1(xy)\n        h = self.norm1(h)\n        h = self.dense2(h)\n        h = self.norm2(h)\n        h = self.dense3(h)\n        h = self.norm3(h)\n        \n        # Add residual connection\n        h = h + self.dense_residual(xy)\n        \n        # Final output\n        u = self.dense4(h)\n        return u\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:01:41.522127Z","iopub.execute_input":"2024-12-12T15:01:41.522818Z","iopub.status.idle":"2024-12-12T15:01:41.530752Z","shell.execute_reply.started":"2024-12-12T15:01:41.522783Z","shell.execute_reply":"2024-12-12T15:01:41.529788Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"class PINN(tf.keras.Model):\n    def __init__(self, l2_lambda=1e-3, dropout_rate=0.2):\n        super(PINN, self).__init__()\n        \n        # Define the L2 regularizer\n        l2_regularizer = tf.keras.regularizers.L2(l2_lambda)\n        \n        # Layers with L2 regularization\n        self.dense1 = tf.keras.layers.Dense(\n            128, activation='tanh', \n            kernel_initializer='glorot_normal', \n            kernel_regularizer=l2_regularizer\n        )\n        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)  # Dropout layer\n        self.norm1 = tf.keras.layers.LayerNormalization()\n        \n        self.dense2 = tf.keras.layers.Dense(\n            128, activation='tanh', \n            kernel_initializer='glorot_normal', \n            kernel_regularizer=l2_regularizer\n        )\n        \n        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)  # Dropout layer\n        self.norm2 = tf.keras.layers.LayerNormalization()\n        \n        self.dense3 = tf.keras.layers.Dense(\n            128, activation='tanh', \n            kernel_initializer='glorot_normal', \n            kernel_regularizer=l2_regularizer\n        )\n        self.dropout3 = tf.keras.layers.Dropout(dropout_rate)  # Dropout layer\n        self.norm3 = tf.keras.layers.LayerNormalization()\n        \n        self.dense_residual = tf.keras.layers.Dense(\n            50, activation='linear', \n            kernel_initializer='glorot_normal', \n            kernel_regularizer=l2_regularizer\n        )\n        \n        self.dense4 = tf.keras.layers.Dense(\n            1, kernel_initializer='glorot_normal', \n            kernel_regularizer=l2_regularizer\n        )\n\n    def call(self, x, y, training=False):\n        # Ensure x and y are 1D tensors\n        x = tf.reshape(x, [-1])  # Shape: (batch_size,)\n        y = tf.reshape(y, [-1])  # Shape: (batch_size,)\n        x = tf.expand_dims(x, axis=-1)  # Shape: (batch_size, 1)\n        y = tf.expand_dims(y, axis=-1)  # Shape: (batch_size, 1)\n\n        # Concatenate inputs\n        xy = tf.concat([x, y], axis=1)  # Shape: (batch_size, 2)\n\n        # Forward pass with Dropout\n        h = self.dense1(xy)\n        h = self.dropout1(h, training=training)  # Apply dropout\n        h = self.norm1(h)\n        h = self.dense2(h)\n        h = self.dropout2(h, training=training)  # Apply dropout\n        h = self.norm2(h)\n        h = self.dense3(h)\n        h = self.dropout3(h, training=training)  # Apply dropout\n        h = self.norm3(h)\n        \n        # Add residual connection\n        h = h + self.dense_residual(xy)\n        \n        # Final output\n        u = self.dense4(h)\n        return u\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:13.400805Z","iopub.execute_input":"2024-12-13T06:13:13.401342Z","iopub.status.idle":"2024-12-13T06:13:13.413543Z","shell.execute_reply.started":"2024-12-13T06:13:13.401292Z","shell.execute_reply":"2024-12-13T06:13:13.412402Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"model = PINN()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T05:59:35.230330Z","iopub.execute_input":"2024-12-13T05:59:35.231190Z","iopub.status.idle":"2024-12-13T05:59:35.249735Z","shell.execute_reply.started":"2024-12-13T05:59:35.231155Z","shell.execute_reply":"2024-12-13T05:59:35.248903Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def pde_loss(model, train_interior, eps):\n    \"\"\"\n    Calculate the PDE residual loss using automatic differentiation.\n    \n    Args:\n        model (tf.keras.Model): Neural network model\n        train_interior (tf.Tensor): Interior training points\n        eps (float): Diffusion coefficient\n    \n    Returns:\n        tf.Tensor: Mean squared PDE residual\n    \"\"\"\n    x = tf.expand_dims(train_interior[:, 0], axis=1)\n    y = tf.expand_dims(train_interior[:, 1], axis=1)\n    \n    # Calculate derivatives using automatic differentiation\n    with tf.GradientTape(persistent=True) as tape1:\n        tape1.watch(x)\n        tape1.watch(y)\n        with tf.GradientTape(persistent=True) as tape2:\n            tape2.watch(x)\n            tape2.watch(y)\n            u = model(tf.concat([x, y], axis=1))\n        grad_x = tape2.gradient(u, x)  # First derivatives\n        grad_y = tape2.gradient(u, y)\n    grad2_x = tape1.gradient(grad_x, x)  # Second derivatives\n    grad2_y = tape1.gradient(grad_y, y)\n    \n    # Calculate PDE residual: -eps*(uxx + uyy) + 2*ux + 3*uy - f(x,y)\n    residual = -eps * (grad2_x + grad2_y) + 2 * grad_x + 3 * grad_y - f(x, y)\n    return tf.reduce_mean(tf.square(residual))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:17.214184Z","iopub.execute_input":"2024-12-13T06:13:17.214529Z","iopub.status.idle":"2024-12-13T06:13:17.221240Z","shell.execute_reply.started":"2024-12-13T06:13:17.214499Z","shell.execute_reply":"2024-12-13T06:13:17.220196Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"def bc_loss(model, x_bd):\n    \"\"\"\n    Calculate the boundary condition loss.\n    \n    Args:\n        model (tf.keras.Model): Neural network model\n        x_bd (tf.Tensor): Boundary points\n    \n    Returns:\n        tf.Tensor: Mean squared error at boundary points\n    \"\"\"\n    # Boundary Loss\n    u_pred = model(x_bd)\n    x = tf.expand_dims(x_bd[:, 0], axis=1)\n    y = tf.expand_dims(x_bd[:, 1], axis=1)\n    u_exact = u_bc(x, y)\n    \n    return tf.reduce_mean(tf.square(u_pred - u_exact))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:18.732989Z","iopub.execute_input":"2024-12-13T06:13:18.733671Z","iopub.status.idle":"2024-12-13T06:13:18.738263Z","shell.execute_reply.started":"2024-12-13T06:13:18.733639Z","shell.execute_reply":"2024-12-13T06:13:18.737331Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# Early stopping class\nclass EarlyStopping:\n    def __init__(self, patience=5):\n        self.patience = patience\n        self.best_loss = float('inf')\n        self.wait = 0\n\n    def should_stop(self, current_loss):\n        if current_loss < self.best_loss:\n            self.best_loss = current_loss\n            self.wait = 0\n        else:\n            self.wait += 1\n        return self.wait >= self.patience","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:13:19.783446Z","iopub.execute_input":"2024-12-13T06:13:19.783752Z","iopub.status.idle":"2024-12-13T06:13:19.788885Z","shell.execute_reply.started":"2024-12-13T06:13:19.783728Z","shell.execute_reply":"2024-12-13T06:13:19.787990Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"def train(model, epochs, train_interior, train_boundary, eps, beta, lr_initial):\n    \"\"\"\n    Train the PINN model.\n    \n    Args:\n        model (tf.keras.Model): Neural network model\n        epochs (int): Number of training epochs\n        train_interior (tf.Tensor): Interior training points\n        train_boundary (tf.Tensor): Boundary training points\n        eps (float): Diffusion coefficient\n        beta (float): Weight for boundary condition loss\n        lr_initial (float): Initial learning rate\n    \"\"\"\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=lr_initial,\n    decay_steps=1000,  # Number of steps before the learning rate decays\n    decay_rate=0.9,    # The rate at which the learning rate will decay\n    staircase=True     # Whether to apply the decay in discrete steps\n)\n    optimizer = tf.optimizers.Adam(learning_rate=lr_schedule)\n    early_stop = EarlyStopping(patience=5)\n    \n    for epoch in range(epochs):\n        # Compute gradients and update model parameters\n        with tf.GradientTape() as tape:\n            loss_pde = pde_loss(model, train_interior, eps)\n            loss_bc = bc_loss(model, train_boundary)\n            total_loss = loss_pde + beta * loss_bc\n            \n        grads = tape.gradient(total_loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n        \n        # Print training progress\n        if epoch % 1000 == 0 or epoch == epochs-1:\n            print(f\"Epoch {epoch}, Total Loss: {total_loss.numpy()}, PDE Loss: {loss_pde.numpy()}, BC Loss: {loss_bc.numpy()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:14:03.235771Z","iopub.execute_input":"2024-12-13T06:14:03.236159Z","iopub.status.idle":"2024-12-13T06:14:03.243902Z","shell.execute_reply.started":"2024-12-13T06:14:03.236128Z","shell.execute_reply":"2024-12-13T06:14:03.242993Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"def create_submission(model, test_path, output_path):\n    \"\"\"\n    Create submission file with model predictions.\n    \n    Args:\n        model (tf.keras.Model): Trained neural network model\n        test_path (str): Path to test data CSV file\n        output_path (str): Path for output submission file\n    \"\"\"\n    test_data = pd.read_csv(test_path)\n    xy = test_data[['x', 'y']].values\n    predictions = model.predict(xy)\n    test_data['u'] = predictions\n    test_data.to_csv(output_path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:14:05.866754Z","iopub.execute_input":"2024-12-13T06:14:05.867146Z","iopub.status.idle":"2024-12-13T06:14:05.872401Z","shell.execute_reply.started":"2024-12-13T06:14:05.867114Z","shell.execute_reply":"2024-12-13T06:14:05.871330Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:14:06.543170Z","iopub.execute_input":"2024-12-13T06:14:06.544031Z","iopub.status.idle":"2024-12-13T06:14:06.558515Z","shell.execute_reply.started":"2024-12-13T06:14:06.543994Z","shell.execute_reply":"2024-12-13T06:14:06.557800Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m90\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121\u001b[0m (484.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121</span> (484.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121\u001b[0m (484.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121</span> (484.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"# --- MAIN EXECUTION ---\n# Generate interior training points\nx_train_interior = np.random.uniform(x_min, x_max, (N_interior, 1))\ny_train_interior = np.random.uniform(y_min, y_max, (N_interior, 1))\ntrain_interior = tf.convert_to_tensor(np.hstack([x_train_interior, y_train_interior]), dtype=tf.float32)\n\n# Generate boundary training points\nx_boundary, y_boundary = generate_boundary_points(x_min, x_max, y_min, y_max, N_boundary)\ntrain_boundary = tf.convert_to_tensor(np.hstack([x_boundary, y_boundary]), dtype=tf.float32)\n\n# Create and train model on specified device\nwith tf.device(device):\n    # Define neural network architecture\n    model = tf.keras.Sequential([\n        tf.keras.layers.InputLayer(input_shape=(2,)),\n        *[tf.keras.layers.Dense(units, activation='tanh') for units in layers[1:-1]],\n        tf.keras.layers.Dense(1)\n    ])\n    \n    # Train the model\n    train(model, epochs, train_interior, train_boundary, eps, beta, lr_initial)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:14:07.183849Z","iopub.execute_input":"2024-12-13T06:14:07.184206Z","iopub.status.idle":"2024-12-13T06:22:16.186252Z","shell.execute_reply.started":"2024-12-13T06:14:07.184178Z","shell.execute_reply":"2024-12-13T06:22:16.185280Z"}},"outputs":[{"name":"stdout","text":"Epoch 0, Total Loss: 12.44084358215332, PDE Loss: 12.417240142822266, BC Loss: 0.023603124544024467\nEpoch 1000, Total Loss: 0.11585079878568649, PDE Loss: 0.006468627136200666, BC Loss: 0.10938217490911484\nEpoch 2000, Total Loss: 0.09852267801761627, PDE Loss: 0.0029851424042135477, BC Loss: 0.09553753584623337\nEpoch 3000, Total Loss: 0.09567185491323471, PDE Loss: 0.002423297381028533, BC Loss: 0.09324856102466583\nEpoch 4000, Total Loss: 0.09447090327739716, PDE Loss: 0.001969624776393175, BC Loss: 0.09250127524137497\nEpoch 5000, Total Loss: 0.09634186327457428, PDE Loss: 0.0010609515011310577, BC Loss: 0.09528090804815292\nEpoch 6000, Total Loss: 0.09235922247171402, PDE Loss: 0.0015017822152003646, BC Loss: 0.09085743874311447\nEpoch 7000, Total Loss: 0.09100686013698578, PDE Loss: 0.0018544330960139632, BC Loss: 0.08915242552757263\nEpoch 8000, Total Loss: 0.08952370285987854, PDE Loss: 0.001773103722371161, BC Loss: 0.08775059878826141\nEpoch 9000, Total Loss: 0.08813782781362534, PDE Loss: 0.0020919116213917732, BC Loss: 0.08604591339826584\nEpoch 9999, Total Loss: 0.08713652938604355, PDE Loss: 0.0017480822280049324, BC Loss: 0.08538844436407089\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_submission(model, test_path, submission_path)  # Generating csv file for submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:23:33.624846Z","iopub.execute_input":"2024-12-13T06:23:33.625244Z","iopub.status.idle":"2024-12-13T06:23:41.023293Z","shell.execute_reply.started":"2024-12-13T06:23:33.625214Z","shell.execute_reply":"2024-12-13T06:23:41.022464Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 988us/step\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndef compute_l2_error(test_file):\n    # Load test data\n    data = pd.read_csv(test_file)\n    # Extract true and predicted values\n    u_pred = data['u'].values  # Replace with the column name for predicted values\n    u_true = np.array([f(x, y) for x, y in zip(data['x'], data['y'])])  # Compute true solution for each (x, y)\n    # Compute l2 error\n    l2_error = np.sqrt(np.mean((u_pred - u_true) ** 2))\n    return l2_error\n\n# Example usage\ntest_file = \"/kaggle/working/submission.csv\"  # Replace with your test file path\nl2_error = compute_l2_error(test_file)\nprint(f\"L2 Error: {l2_error}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T06:23:43.379255Z","iopub.execute_input":"2024-12-13T06:23:43.380118Z","iopub.status.idle":"2024-12-13T06:23:45.025683Z","shell.execute_reply.started":"2024-12-13T06:23:43.380078Z","shell.execute_reply":"2024-12-13T06:23:45.024762Z"}},"outputs":[{"name":"stdout","text":"L2 Error: 3.0745425679990412\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom fastvpinns import VPINN\n\n# Define the PDE: Convection-Diffusion Equation\ndef convection_diffusion_residual(u, x, y, u_x, u_y, u_xx, u_yy, eps, beta):\n    \"\"\"\n    Residual for the convection-diffusion equation:\n    -eps * (u_xx + u_yy) + beta[0] * u_x + beta[1] * u_y\n    \"\"\"\n    return -eps * (u_xx + u_yy) + beta[0] * u_x + beta[1] * u_y\n\n# Generate training data\nx_min, x_max, y_min, y_max = 0, 1, 0, 1\nN_train = 1000  # Number of training points\nx_train = np.random.uniform(x_min, x_max, (N_train, 1))\ny_train = np.random.uniform(y_min, y_max, (N_train, 1))\ntrain_points = np.hstack([x_train, y_train])\n\n# PDE parameters\neps = 0.01\nbeta = [1.0, 1.0]\n\n# Define the VPINN model\nmodel = VPINN(\n    input_dim=2,           # (x, y)\n    output_dim=1,          # u(x, y)\n    layers=[64, 64, 64],   # Hidden layers\n    activation='tanh',     # Activation function\n    num_test_funcs=10      # Number of test functions\n)\n\n# Compile the model with the variational residual\nmodel.compile(\n    residual_fn=lambda u, x, y, u_x, u_y, u_xx, u_yy: convection_diffusion_residual(\n        u, x, y, u_x, u_y, u_xx, u_yy, eps, beta\n    ),\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n    metric='mse'\n)\n\n# Train the model\nmodel.fit(train_points, epochs=5000, batch_size=64)\n\n# Predict on test data\ntest_points = np.random.uniform([x_min, y_min], [x_max, y_max], (500, 2))\npredictions = model.predict(test_points)\n\n# Save predictions for submission\nimport pandas as pd\nsubmission = pd.DataFrame(test_points, columns=['x', 'y'])\nsubmission['u_pred'] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}